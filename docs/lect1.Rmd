---
title: 'Эконометрика #1'
author: "Mikhail Plekhanov"
date: "13.04.2015"
output: html_document
---

## Эконометрика на одном слайде

Вопросы:

- Как устроен мир? Как переменная $x$ влияет на переменную $y$?
- Что будет завтра? Как спрогнозировать переменную $y$?

Ответы на эти вопросы мы получаем с помощью моделей.

**Модель** - формула для объясняемой переменной.

Например:
$$
y_{i} = \beta_{1} +  \beta_{2}x_{i} + \epsilon_{i}
$$

## Основные типы данных

- временные ряды
- перекрестные данные
- панельные данные

Временные ряды:

```{r kable, echo=FALSE}
library(knitr)
year <- c(2010, 2011, 2012, 2013)
popul <- c(142962, 142914, 143103, 143395)
unempl <- c(7.4, 6.5, 5.5, 5.5)
df = data.frame(year, popul, unempl)
colnames(df) <- c('Год', 'Население (тыс. чел.)', 'Безработица (%)')
kable(df)
```

Перекрестная выборка:

<!-- TODO/FIXME Таблица с олимпиадой -->

Панельные данные -  сочетание первых двух.

## Данные - обозначения

- одна зависимая (объясняемая) переменная: $y$
- несколько регрессоров (объясняющих переменных): $x$, $z$...
- по каждой переменной $n$ наблюдение: $y_1$, $y_2$, ... , $y_n$

## Данные - пример

Исторические данные 1920-x годов

```{r, echo=FALSE}
head(cars)
```

## Всегда изображайте данные!

Никакой эконометрический анализ не заменит простого графического анализа. Вы можете выявить простым графическим анализом то, что выявить вслепую без графиков эконометрически очень сложно.

```{r, echo=FALSE}
plot(cars$speed, cars$dist, main='Данные по машинах 1920-х годов', ylab = 'Длина тормозного пути (м)', xlab='Скорость машины (км/ч')
grid()
```

Видим, чем больше скорость, тем больше длина тормозного пути.

## Модель

Пример: $y_{i} = \beta_{1} + \beta_{2}x_{i}+\epsilon_{i}$

- наблюдаемы переменные: $y$, $x$
- неизвестные параметры: $\beta_1$, $\beta_2$
- случайная составляющая, ошибка: $\epsilon$

План действий:

- построить адекватную модель
- получить оценки неизвестных параметров: $\hat{\beta_{1}}$, $\hat{\beta_{2}}$
- прогнозировать, заменив неизвестные параметры на оценки: $\hat{y_{i}} = \hat{\beta_{1}} + \hat{\beta_{2}}$

## Метод наименьших квадратов

Это способ получить оценки неизвестных параметров модели, исходя из реальных данных. Если мы получили какие-то оценки $\hat{\beta_{1}}$, $\hat{\beta_{2}}$, то естественно у нас возникает такое понятие как *ошибка прогноза*:

$$\hat{\epsilon_{i}} = y_{i} - \hat{y_{i}}$$

$\hat{\epsilon_{i}}$ - это разница между фактическим наблюдением $y_{i}$ и прогнозом $\hat{y_{i}}$.

И, естесственно, возникает суммарная ошибка прогноза. Чтобы ошибки не компенсировали друг друга, возведем их в квадрат и посчитаем *сумму квадратов ошибок прогноза*:

$$Q(\hat{\beta_{1}}, \hat{\beta_{2}}) = \sum\limits_{i=1}^n \hat{\epsilon_{i}}^2 = \sum\limits_{i=1}^n (y_{i} - \hat{y_{i}})^2$$

Суть МНК: возьмите в качестве оценок такие $\hat{\beta_{1}}$, $\hat{\beta_{2}}$, при которых сумма квадратов ошибок прогноза $Q$ минимальна.